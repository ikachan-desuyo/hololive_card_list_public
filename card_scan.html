<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨èµ¤ç·šæç”»ï¼ˆèƒŒé¢ã‚«ãƒ¡ãƒ©ï¼‰</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <style>
    canvas {
      border: 1px solid black;
      display: block;
      margin: 10px auto;
    }
  </style>
</head>
<body>
  <h1>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨èµ¤ç·šæç”»ï¼ˆèƒŒé¢ã‚«ãƒ¡ãƒ©ï¼‰</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <canvas id="canvasOutput"></canvas>

  <script>
    let canvas = document.getElementById('canvasOutput');
    let ctx = canvas.getContext('2d');
    let video = null;
    let streaming = false;

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "ğŸ”„ OpenCV.js åˆæœŸåŒ–ä¸­...";

      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "âœ… OpenCV.js èª­ã¿è¾¼ã¿å®Œäº†ï¼";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment" // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®š
        }
      })
      .then(stream => {
        video = document.createElement('video'); // å‹•çš„ã«ãƒ“ãƒ‡ã‚ªè¦ç´ ã‚’ç”Ÿæˆ
        video.srcObject = stream;
        video.play();

        video.addEventListener('loadedmetadata', () => {
          const videoWidth = video.videoWidth;
          const videoHeight = video.videoHeight;

          if (!videoWidth || !videoHeight) {
            console.error("ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®æ˜ åƒã‚µã‚¤ã‚ºã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚");
            alert("ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®æ˜ åƒã‚µã‚¤ã‚ºã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
            return;
          }

          const scaleFactor = 1.5; // æ‹¡å¤§å€ç‡
          canvas.width = videoWidth * scaleFactor;
          canvas.height = videoHeight * scaleFactor;

          streaming = true;
          processVideo();
        });
      })
      .catch(err => {
        console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ", err);
        alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
      });
    }

    function processVideo() {
      if (!streaming) return;

      try {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        let src = cv.imread(canvas);
        let gray = new cv.Mat();
        let blurred = new cv.Mat();
        let edges = new cv.Mat();

        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
        cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);
        cv.Canny(blurred, edges, 50, 150);

        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let maxArea = 0;
        let maxContour = null;
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);
          if (area > maxArea) {
            maxArea = area;
            maxContour = cnt;
          }
        }

        if (maxContour) {
          let contoursColor = new cv.Scalar(255, 0, 0, 255); // èµ¤è‰²
          cv.drawContours(src, contours, -1, contoursColor, 2);
        }

        cv.imshow('canvasOutput', src);

        src.delete(); gray.delete(); blurred.delete(); edges.delete();
        contours.delete(); hierarchy.delete();

      } catch (error) {
        console.error("Error in processVideo:", error);
      } finally {
        if (streaming) requestAnimationFrame(processVideo);
      }
    }
  </script>
</body>
</html>