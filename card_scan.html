<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºï¼ˆèµ¤ç·šæ˜ åƒè¡¨ç¤ºæ©Ÿèƒ½è¿½åŠ ï¼‰</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <style>
    video { display: none; }
    canvas { 
      border: 1px solid black; 
      display: block; 
      margin: 10px auto; 
    }
    button { display: block; margin: 20px auto; padding: 15px 30px; font-size: 20px; }
  </style>
</head>
<body>
  <h1>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºï¼ˆèµ¤ç·šæ˜ åƒè¡¨ç¤ºæ©Ÿèƒ½è¿½åŠ ï¼‰</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvasOutput"></canvas>
  <button id="mode1-button">æ”¹å–„æ¡ˆ1: èµ¤æ è¡¨ç¤º</button>
  <button id="red-line-button">èµ¤ç·šæ˜ åƒè¡¨ç¤º</button>

  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvasOutput');
    let ctx = canvas.getContext('2d');
    let streaming = false;
    let currentMode = 1; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯èµ¤æ è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰

    // å„ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ
    document.getElementById('mode1-button').addEventListener('click', () => setMode(1)); // èµ¤æ è¡¨ç¤º
    document.getElementById('red-line-button').addEventListener('click', () => setMode(2)); // èµ¤ç·šæ˜ åƒè¡¨ç¤º

    function setMode(mode) {
      currentMode = mode;
      console.log(`ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: ${mode === 1 ? "èµ¤æ è¡¨ç¤º" : "èµ¤ç·šæ˜ åƒè¡¨ç¤º"}`);
    }

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "ğŸ”„ OpenCV.js åˆæœŸåŒ–ä¸­...";
      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "âœ… OpenCV.js èª­ã¿è¾¼ã¿å®Œäº†ï¼";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" }
      }).then(stream => {
        video.srcObject = stream;
        video.play();
        streaming = true;
        video.addEventListener('loadedmetadata', () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          processVideo();
        });
      }).catch(err => {
        console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ", err);
        alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
      });
    }

    function processVideo() {
      if (!streaming) return;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      let src = cv.imread(canvas);

      if (currentMode === 1) {
        detectWithRedFrames(src); // èµ¤æ è¡¨ç¤º
      } else if (currentMode === 2) {
        showRedLineImage(src); // èµ¤ç·šæ˜ åƒè¡¨ç¤º
      }

      cv.imshow('canvasOutput', src);
      src.delete();
      requestAnimationFrame(processVideo);
    }

    function detectWithRedFrames(src) {
      // èµ¤æ ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º
      let gray = new cv.Mat();
      let edges = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.Canny(gray, edges, 50, 150);

      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      for (let i = 0; i < contours.size(); ++i) {
        let cnt = contours.get(i);
        let rect = cv.boundingRect(cnt);
        cv.rectangle(src, new cv.Point(rect.x, rect.y), new cv.Point(rect.x + rect.width, rect.y + rect.height), [255, 0, 0, 255], 2);
      }

      contours.delete(); hierarchy.delete(); gray.delete(); edges.delete();
    }

    function showRedLineImage(src) {
      // èµ¤ç·šæ˜ åƒã‚’è¡¨ç¤ºï¼ˆCannyã‚¨ãƒƒã‚¸æ¤œå‡ºã®çµæœï¼‰
      let gray = new cv.Mat();
      let edges = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.Canny(gray, edges, 50, 150);

      // ã‚¨ãƒƒã‚¸ç”»åƒã‚’ãã®ã¾ã¾è¡¨ç¤º
      cv.cvtColor(edges, src, cv.COLOR_GRAY2RGBA);

      gray.delete(); edges.delete();
    }
  </script>
</body>
</html>