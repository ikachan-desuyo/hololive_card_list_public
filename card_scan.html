<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRã¨ã‚«ãƒ¼ãƒ‰æ æ¤œå‡º</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@2.1.1/dist/tesseract.min.js"></script>
  <style>
    canvas {
      border: 1px solid black;
      display: block;
      margin: 10px auto;
    }
    #ocrResult {
      text-align: center;
      font-size: 1.2em;
      font-weight: bold;
      margin-top: 20px;
    }
    button {
      display: block;
      margin: 10px auto;
      padding: 10px 20px;
      font-size: 1em;
    }
  </style>
</head>
<body>
  <h1>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRã¨ã‚«ãƒ¼ãƒ‰æ æ¤œå‡º</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <canvas id="canvasOutput"></canvas>
  <button id="ocrButton">OCRã‚’é–‹å§‹ã™ã‚‹</button>
  <div id="ocrResult">èªè­˜æ–‡å­—åˆ—: <span id="recognizedText">-</span></div>

  <script>
    let canvas = document.getElementById('canvasOutput');
    let ctx = canvas.getContext('2d');
    let streaming = false;
    let videoWidth = 640; // åˆæœŸå€¤
    let videoHeight = 480; // åˆæœŸå€¤
    let video;

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "ğŸ”„ OpenCV.js åˆæœŸåŒ–ä¸­...";

      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "âœ… OpenCV.js èª­ã¿è¾¼ã¿å®Œäº†ï¼";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment" // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®š
        }
      })
      .then(stream => {
        video = document.createElement('video');
        video.srcObject = stream;
        video.play();

        video.addEventListener('loadedmetadata', () => {
          // æ˜ åƒã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’å–å¾—ã—ã¦Canvasã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´
          videoWidth = video.videoWidth;
          videoHeight = video.videoHeight;
          canvas.width = videoWidth;
          canvas.height = videoHeight;

          streaming = true;
          processVideo();
        });
      })
      .catch(err => {
        console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ", err);
        alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
      });
    }

    function processVideo() {
      if (!streaming) return;

      // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’Canvasã«æç”»
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // OpenCVã§ç”»åƒå‡¦ç†
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      try {
        // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        // ã¼ã‹ã—å‡¦ç†
        cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

        // ã‚¨ãƒƒã‚¸æ¤œå‡º
        cv.Canny(blurred, edges, 50, 150);

        // è¼ªéƒ­æ¤œå‡º
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        // æœ€å¤§é¢ç©ã®è¼ªéƒ­ã‚’æ¢ã™
        let maxArea = 0;
        let maxContour = null;
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);
          if (area > maxArea) {
            maxArea = area;
            maxContour = cnt;
          }
        }

        if (maxContour) {
          // æœ€å¤§è¼ªéƒ­ã‚’èµ¤ç·šã§æç”»
          const color = new cv.Scalar(255, 0, 0, 255);
          cv.drawContours(src, contours, -1, color, 2);
        }

        // çµæœã‚’Canvasã«æç”»
        cv.imshow('canvasOutput', src);

      } catch (error) {
        console.error("ãƒ“ãƒ‡ã‚ªå‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼: ", error);
      } finally {
        // ãƒ¡ãƒ¢ãƒªè§£æ”¾
        src.delete(); gray.delete(); blurred.delete(); edges.delete();
      }

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
      if (streaming) requestAnimationFrame(processVideo);
    }

    document.getElementById('ocrButton').addEventListener('click', () => {
      // OCRå‡¦ç†ã‚’é–‹å§‹
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      try {
        // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        // ã¼ã‹ã—å‡¦ç†
        cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

        // ã‚¨ãƒƒã‚¸æ¤œå‡º
        cv.Canny(blurred, edges, 50, 150);

        // è¼ªéƒ­æ¤œå‡º
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        // æœ€å¤§é¢ç©ã®è¼ªéƒ­ã‚’æ¢ã™
        let maxArea = 0;
        let maxContour = null;
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);
          if (area > maxArea) {
            maxArea = area;
            maxContour = cnt;
          }
        }

        if (maxContour) {
          const boundingBox = cv.boundingRect(maxContour);
          const roi = src.roi(boundingBox);

          // OCRã‚’éåŒæœŸã§å®Ÿè¡Œ
          recognizeText(roi).then(() => {
            roi.delete(); // ãƒ¡ãƒ¢ãƒªè§£æ”¾
          });
        }

      } catch (error) {
        console.error("OCRå‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼: ", error);
      } finally {
        // ãƒ¡ãƒ¢ãƒªè§£æ”¾
        src.delete(); gray.delete(); blurred.delete(); edges.delete();
      }
    });

    async function recognizeText(image) {
      try {
        // Tesseract.jsã§OCRã‚’å®Ÿè¡Œ
        const result = await Tesseract.recognize(image.data, 'eng', {
          logger: info => console.log(info) // ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        });

        // èªè­˜æ–‡å­—åˆ—ã‚’æ›´æ–°
        document.getElementById('recognizedText').innerText = result.data.text.trim();
      } catch (err) {
        console.error("OCRã‚¨ãƒ©ãƒ¼:", err);
      }
    }
  </script>
</body>
</html>