<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨ãƒˆãƒªãƒŸãƒ³ã‚°</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <style>
    video {
      display: none; /* æ˜ åƒã‚’éè¡¨ç¤ºã«è¨­å®š */
    }
    canvas {
      border: 1px solid black;
      display: block;
      margin: 10px auto;
    }
    #trimming-button {
      display: block;
      margin: 20px auto;
      padding: 10px 20px;
      font-size: 18px;
    }
  </style>
</head>
<body>
  <h1>ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨ãƒˆãƒªãƒŸãƒ³ã‚°</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvasOutput"></canvas>
  <button id="trimming-button">ãƒˆãƒªãƒŸãƒ³ã‚°å®Ÿè¡Œ</button>
  <canvas id="trimmedCanvas"></canvas>

  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvasOutput');
    let trimmedCanvas = document.getElementById('trimmedCanvas');
    let ctx = canvas.getContext('2d');
    let streaming = false;

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "ğŸ”„ OpenCV.js åˆæœŸåŒ–ä¸­...";

      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "âœ… OpenCV.js èª­ã¿è¾¼ã¿å®Œäº†ï¼";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment" // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®š
        }
      })
      .then(stream => {
        video.srcObject = stream;
        video.play();
        streaming = true;

        video.addEventListener('loadedmetadata', () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;

          // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ æ¤œå‡ºã‚’é–‹å§‹
          processVideo();
        });
      })
      .catch(err => {
        console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ", err);
        alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
      });
    }

    function processVideo() {
      if (!streaming) return;

      // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’Canvasã«æç”»
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // OpenCVã§ç”»åƒå‡¦ç†
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

      // ã¼ã‹ã—å‡¦ç†
      cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

      // ã‚¨ãƒƒã‚¸æ¤œå‡º
      cv.Canny(blurred, edges, 50, 150);

      // è¼ªéƒ­æ¤œå‡º
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let bestContour = null;
      const targetAspectRatio = 88 / 63; // ã‚«ãƒ¼ãƒ‰ã®ç¸¦æ¨ªæ¯”ï¼ˆç´„1.4ï¼‰
      const tolerance = 0.1; // ç¸¦æ¨ªæ¯”ã®è¨±å®¹ç¯„å›²ï¼ˆ10%ï¼‰

      for (let i = 0; i < contours.size(); ++i) {
        let contour = contours.get(i);

        // å¤šè§’å½¢è¿‘ä¼¼ã§è¼ªéƒ­ã‚’å˜ç´”åŒ–
        let approx = new cv.Mat();
        cv.approxPolyDP(contour, approx, 0.02 * cv.arcLength(contour, true), true);

        // é ‚ç‚¹ãŒ4ã¤ã§ã‚ã‚‹å ´åˆï¼ˆé•·æ–¹å½¢ã‚’æ¢ã™ï¼‰
        if (approx.rows === 4) {
          let rect = cv.boundingRect(approx);

          // ç¸¦æ¨ªæ¯”ã‚’è¨ˆç®—
          let aspectRatio = rect.height / rect.width;
          if (Math.abs(aspectRatio - targetAspectRatio) < tolerance) {
            bestContour = approx;
            break; // æœ€åˆã«è¦‹ã¤ã‹ã£ãŸé©åˆ‡ãªè¼ªéƒ­ã‚’ä½¿ç”¨
          }
        }

        approx.delete();
      }

      if (bestContour) {
        // èµ¤ç·šã§è¼ªéƒ­ã‚’è¡¨ç¤º
        let contoursColor = new cv.Scalar(255, 0, 0, 255);
        cv.drawContours(src, new cv.MatVector([bestContour]), -1, contoursColor, 2);
      }

      // çµæœã‚’Canvasã«æç”»
      cv.imshow('canvasOutput', src);

      // ãƒ¡ãƒ¢ãƒªè§£æ”¾
      src.delete(); gray.delete(); blurred.delete(); edges.delete();
      contours.delete(); hierarchy.delete();

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
      if (streaming) requestAnimationFrame(processVideo);
    }

    // ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’å®Ÿè¡Œ
    document.getElementById('trimming-button').addEventListener('click', () => {
      // ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

      // ã¼ã‹ã—å‡¦ç†
      cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

      // ã‚¨ãƒƒã‚¸æ¤œå‡º
      cv.Canny(blurred, edges, 50, 150);

      // è¼ªéƒ­æ¤œå‡º
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let bestContour = null;
      const targetAspectRatio = 88 / 63; // ã‚«ãƒ¼ãƒ‰ã®ç¸¦æ¨ªæ¯”ï¼ˆç´„1.4ï¼‰
      const tolerance = 0.1;

      for (let i = 0; i < contours.size(); ++i) {
        let contour = contours.get(i);

        let approx = new cv.Mat();
        cv.approxPolyDP(contour, approx, 0.02 * cv.arcLength(contour, true), true);

        if (approx.rows === 4) {
          let rect = cv.boundingRect(approx);
          let aspectRatio = rect.height / rect.width;
          if (Math.abs(aspectRatio - targetAspectRatio) < tolerance) {
            bestContour = approx;
            break;
          }
        }

        approx.delete();
      }

      if (bestContour) {
        let rect = cv.boundingRect(bestContour);
        let trimmed = src.roi(rect);

        trimmedCanvas.width = rect.width;
        trimmedCanvas.height = rect.height;
        cv.imshow(trimmedCanvas, trimmed);

        trimmed.delete();
      }

      src.delete(); gray.delete(); blurred.delete(); edges.delete();
      contours.delete(); hierarchy.delete();
    });
  </script>
</body>
</html>