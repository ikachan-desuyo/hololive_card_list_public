<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨èµ¤ç·šæç”»</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <style>
    canvas {
      border: 1px solid black;
      display: block;
      margin: 10px auto;
    }
  </style>
</head>
<body>
  <h1>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¼ãƒ‰æ æ¤œå‡ºã¨èµ¤ç·šæç”»</h1>
  <div id="opencv-status" style="font-weight: bold; margin: 1em;"></div>
  <canvas id="canvasOutput"></canvas>

  <script>
    let canvas = document.getElementById('canvasOutput');
    let ctx = canvas.getContext('2d');
    let streaming = false;
    let videoWidth = 640; // åˆæœŸå€¤
    let videoHeight = 480; // åˆæœŸå€¤
    let video;

    function onOpenCvReady() {
      const statusEl = document.getElementById("opencv-status");
      statusEl.innerText = "ğŸ”„ OpenCV.js åˆæœŸåŒ–ä¸­...";

      cv['onRuntimeInitialized'] = () => {
        statusEl.innerText = "âœ… OpenCV.js èª­ã¿è¾¼ã¿å®Œäº†ï¼";
        startCamera();
      };
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment" // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®š
        }
      })
      .then(stream => {
        video = document.createElement('video');
        video.srcObject = stream;
        video.play();

        video.addEventListener('loadedmetadata', () => {
          // æ˜ åƒã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’å–å¾—ã—ã¦Canvasã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´
          videoWidth = video.videoWidth;
          videoHeight = video.videoHeight;

          // Canvasã‚’ã‚«ãƒ¡ãƒ©æ˜ åƒã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã«åŸºã¥ã„ã¦è¨­å®š
          const scaleFactor = 1.5; // æ‹¡å¤§å€ç‡
          canvas.width = videoWidth * scaleFactor;
          canvas.height = videoHeight * scaleFactor;

          streaming = true;
          processVideo();
        });
      })
      .catch(err => {
        console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ", err);
        alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ã®ã‚«ãƒ¡ãƒ©æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
      });
    }

    function processVideo() {
      if (!streaming) return;

      // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’Canvasã«æç”»
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // OpenCVã§ç”»åƒå‡¦ç†
      let src = cv.imread(canvas);
      let gray = new cv.Mat();
      let blurred = new cv.Mat();
      let edges = new cv.Mat();

      try {
        // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        // ã¼ã‹ã—å‡¦ç†
        cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);

        // ã‚¨ãƒƒã‚¸æ¤œå‡º
        cv.Canny(blurred, edges, 50, 150);

        // è¼ªéƒ­æ¤œå‡º
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        // æœ€å¤§é¢ç©ã®è¼ªéƒ­ã‚’æ¢ã™
        let maxArea = 0;
        let maxContour = null;
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);
          if (area > maxArea) {
            maxArea = area;
            maxContour = cnt;
          }
        }

        if (maxContour) {
          // æœ€å¤§è¼ªéƒ­ã‚’èµ¤ç·šã§æç”»
          const color = new cv.Scalar(255, 0, 0, 255);
          cv.drawContours(src, contours, -1, color, 2);
        }

        // çµæœã‚’Canvasã«æç”»
        cv.imshow('canvasOutput', src);

      } catch (error) {
        console.error("ãƒ“ãƒ‡ã‚ªå‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼: ", error);
      } finally {
        // ãƒ¡ãƒ¢ãƒªè§£æ”¾
        src.delete(); gray.delete(); blurred.delete(); edges.delete();
      }

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
      if (streaming) requestAnimationFrame(processVideo);
    }
  </script>
</body>
</html>